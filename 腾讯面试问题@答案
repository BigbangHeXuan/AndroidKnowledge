内存抖动（代码注意事项）
跨进程通信
动画原理
Https的连接过程，加解密算法的选择，以及为什么？
TCP三次握手
组件化开发流程
如何绕过9.0限制？
堆内存，栈内存理解，栈如何转换成堆？
hashcode（）和 equals（）的作用、区别、联系？
Handler、Looper、MessageQueue、Thread关系？
Hashmap如何解决散列碰撞（必问）？
Hashmap底层为什么是线程不安全的？
硬件加速的实现原理？
handler postDelay这个延迟是怎么实现的？
断点续传实现？
RxJava 变换操作符 map flatMap concatMap buffer？
Android中ClassLoader的种类&特点
性能优化（要求比较细，有实践经验）
代码、资源热修复原理
有没有研究的比较深的技术点？

答案：https://mubu.com/doc/uRmziI6te0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
1、内存抖动（代码注意事项）：
    定义：
    内存抖动是由于短时间内有大量对象进出新生区导致的，它伴随着频繁的GC，gc会大量占用ui线程和cpu资源，会导致app整体卡顿。
    避免发生内存抖动的几点建议：
    尽量避免在循环体内创建对象，应该把对象创建移到循环体外。
    注意自定义View的onDraw()方法会被频繁调用，所以在这里面不应该频繁的创建对象。
    当需要大量使用Bitmap的时候，试着把它们缓存在数组或容器中实现复用。
    对于能够复用的对象，同理可以使用对象池将它们缓存起来。

2、跨进程通信：
    Android中进程和线程的关系？区别？

    线程是CPU调度的最小单元，同时线程是一种有限的系统资源；而进程一般指一个执行单元，在PC和移动设备上指一个程序或者一个应用。
    一般来说，一个App程序至少有一个进程，一个进程至少有一个线程，通俗来讲就是，在App这个工厂里面有一个进程，线程就是里面的生产线，但主线程（即主生产线）只有一条，而子线程（即副生产线）可以有多个。

    进程有自己独立的地址空间，而进程中的线程共享此地址空间，都可以并发执行。
    如何开启多进程？应用是否可以开启N个进程？
      在AndroidManifest中给四大组件指定属性android:process开启多进程模式，在内存允许的条件下可以开启N个进程。

    为何需要IPC？多进程通信可能会出现的问题？

      所有运行在不同进程的四大组件（Activity、Service、Receiver、ContentProvider）共享数据都会失败，这是由于Android为每个应用分配了独立的虚拟机，不同的虚拟机在内存分配上有不同的地址空间，
      这会导致在不同的虚拟机中访问同一个类的对象会产生多份副本。比如常用例子（通过开启多进程获取更大内存空间、两个或者多个应用之间共享数据、微信全家桶）。
      
      一般来说，使用多进程通信会造成如下几方面的问题:
        静态成员和单例模式完全失效：独立的虚拟机造成。
        线程同步机制完全失效：独立的虚拟机造成。
        SharedPreferences的可靠性下降：这是因为Sp不支持两个进程并发进行读写，有一定几率导致数据丢失。
        Application会多次创建：Android系统在创建新的进程时会分配独立的虚拟机，所以这个过程其实就是启动一个应用的过程，自然也会创建新的Application。
    
    Android中IPC方式、各种方式优缺点？

    讲讲AIDL？如何优化多模块都使用AIDL的情况？


    AIDL(Android Interface Definition Language，Android接口定义语言)：如果在一个进程中要调用另一个进程中对象的方法，
    可使用AIDL生成可序列化的参数，AIDL会生成一个服务端对象的代理类，通过它客户端可以实现间接调用服务端对象的方法。
    AIDL的本质是系统提供了一套可快速实现Binder的工具。关键类和方法：
    AIDL接口：继承IInterface。
    Stub类：Binder的实现类，服务端通过这个类来提供服务。
    Proxy类：服务端的本地代理，客户端通过这个类调用服务端的方法。
    asInterface()：客户端调用，将服务端返回的Binder对象，转换成客户端所需要的AIDL接口类型的对象。
    如果客户端和服务端位于同一进程，则直接返回Stub对象本身，否则返回系统封装后的Stub.proxy对象。
    asBinder()：根据当前调用情况返回代理Proxy的Binder对象。
    onTransact()：运行在服务端的Binder线程池中，当客户端发起跨进程请求时，远程请求会通过系统底层封装后交由此方法来处理。
    transact()：运行在客户端，当客户端发起远程请求的同时将当前线程挂起。之后调用服务端的onTransact()直到远程请求返回，当前线程才继续执行。
    当有多个业务模块都需要AIDL来进行IPC，此时需要为每个模块创建特定的aidl文件，那么相应的Service就会很多。必然会出现系统资源耗费严重、应用过度重量级的问题。解决办法是建立Binder连接池，即将每个业务模块的Binder请求统一转发到一个远程Service中去执行，从而避免重复创建Service。

    工作原理：每个业务模块创建自己的AIDL接口并实现此接口，然后向服务端提供自己的唯一标识和其对应的Binder对象。服务端只需要一个Service并提供一个queryBinder接口，它会根据业务模块的特征来返回相应的Binder对象，不同的业务模块拿到所需的Binder对象后就可以进行远程方法的调用了。

    为什么选择Binder？

    为什么选用Binder，在讨论这个问题之前，我们知道Android也是基于Linux内核，Linux现有的进程间通信手段有以下几种：
    管道：在创建时分配一个page大小的内存，缓存区大小比较有限；
    消息队列：信息复制两次，额外的CPU消耗；不合适频繁或信息量大的通信；
    共享内存：无须复制，共享缓冲区直接附加到进程虚拟地址空间，速度快；但进程间的同步问题操作系统无法实现，必须各进程利用同步工具解决；
    套接字：作为更通用的接口，传输效率低，主要用于不同机器或跨网络的通信；
    信号量：常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 不适用于信息交换，更适用于进程中断控制，比如非法内存访问，杀死某个进程等；

    既然有现有的IPC方式，为什么重新设计一套Binder机制呢。主要是出于以下三个方面的考量：

    1、效率：传输效率主要影响因素是内存拷贝的次数，拷贝次数越少，传输速率越高。从Android进程架构角度分析：对于消息队列、Socket和管道来说，
    数据先从发送方的缓存区拷贝到内核开辟的缓存区中，再从内核缓存区拷贝到接收方的缓存区，一共两次拷贝，如图：

    而对于Binder来说，数据从发送方的缓存区拷贝到内核的缓存区，而接收方的缓存区与内核的缓存区是映射到同一块物理地址的，节省了一次数据拷贝的过程，如图：
    共享内存不需要拷贝，Binder的性能仅次于共享内存。
    2、稳定性：上面说到共享内存的性能优于Binder，那为什么不采用共享内存呢，因为共享内存需要处理并发同步问题，容易出现死锁和资源竞争，稳定性较差。Socket虽然是基于C/S架构的，但是它主要是用于网络间的通信且传输效率较低。Binder基于C/S架构 ，Server端与Client端相对独立，稳定性较好。
    3、安全性：传统Linux IPC的接收方无法获得对方进程可靠的UID/PID，从而无法鉴别对方身份；而Binder机制为每个进程分配了UID/PID，且在Binder通信时会根据UID/PID进行有效性检测。

    Binder机制的作用和原理？

      Linux系统将一个进程分为用户空间和内核空间。对于进程之间来说，用户空间的数据不可共享，内核空间的数据可以共享，为了保证安全性和独立性，一个进程不能直接操作或者访问另一个进程，即Android的进程是相互独立、隔离的，这就需要跨进程之间的数据通信方式。普通的跨进程通信方式一般需要2次内存拷贝，如下图所示：

      一次完整的 Binder IPC 通信过程通常是这样：
      首先 Binder 驱动在内核空间创建一个数据接收缓存区。
      接着在内核空间开辟一块内核缓存区，建立内核缓存区和内核中数据接收缓存区之间的映射关系，以及内核中数据接收缓存区和接收进程用户空间地址的映射关系。
      发送方进程通过系统调用 copyfromuser() 将数据 copy 到内核中的内核缓存区，由于内核缓存区和接收进程的用户空间存在内存映射，因此也就相当于把数据发送到了接收进程的用户空间，这样便完成了一次进程间的通信。

      Binder框架中ServiceManager的作用？
      Binder框架 是基于 C/S 架构的。由一系列的组件组成，包括 Client、Server、ServiceManager、Binder驱动，其中 Client、Server、Service Manager 运行在用户空间，Binder 驱动运行在内核空间。如下图所示：
      Server&Client：服务器&客户端。在Binder驱动和Service Manager提供的基础设施上，进行Client-Server之间的通信。
      ServiceManager（如同DNS域名服务器）服务的管理者，将Binder名字转换为Client中对该Binder的引用，使得Client可以通过Binder名字获得Server端中Binder实体的引用。
      Binder驱动（如同路由器）：负责进程之间binder通信的建立，计数管理以及数据的传递交互等底层支持。

      最后，结合[Android跨进程通信：图文详解 Binder机制 ](https://blog.csdn.net/carson_ho/article/details/73560642) 的总结图来综合理解一下：

      Binder 的完整定义
      从进程间通信的角度看，Binder 是一种进程间通信的机制；
      从 Server 进程的角度看，Binder 指的是 Server 中的 Binder 实体对象；
      从 Client 进程的角度看，Binder 指的是 Binder 代理对象，是 Binder 实体对象的一个远程代理；
      从传输过程的角度看，Binder 是一个可以跨进程传输的对象；Binder 驱动会对这个跨越进程边界的对象做一点点特殊处理，自动完成代理对象和本地对象之间的转换。

    手写实现简化版AMS（AIDL实现）


    与Binder相关的几个类的职责:
    IBinder：跨进程通信的Base接口，它声明了跨进程通信需要实现的一系列抽象方法，实现了这个接口就说明可以进行跨进程通信，Client和Server都要实现此接口。
    IInterface：这也是一个Base接口，用来表示Server提供了哪些能力，是Client和Server通信的协议。
    Binder：提供Binder服务的本地对象的基类，它实现了IBinder接口，所有本地对象都要继承这个类。
    BinderProxy：在Binder.java这个文件中还定义了一个BinderProxy类，这个类表示Binder代理对象它同样实现了IBinder接口，不过它的很多实现都交由native层处理。Client中拿到的实际上是这个代理对象。
    Stub：这个类在编译aidl文件后自动生成，它继承自Binder，表示它是一个Binder本地对象；它是一个抽象类，实现了IInterface接口，表明它的子类需要实现Server将要提供的具体能力（即aidl文件中声明的方法）。
    Proxy：它实现了IInterface接口，说明它是Binder通信过程的一部分；它实现了aidl中声明的方法，但最终还是交由其中的mRemote成员来处理，说明它是一个代理对象，mRemote成员实际上就是BinderProxy。
    aidl文件只是用来定义C/S交互的接口，Android在编译时会自动生成相应的Java类，生成的类中包含了Stub和Proxy静态内部类，用来封装数据转换的过程，实际使用时只关心具体的Java接口类即可。为什么Stub和Proxy是静态内部类呢？这其实只是为了将三个类放在一个文件中，提高代码的聚合性。通过上面的分析，我们其实完全可以不通过aidl，手动编码来实现Binder的通信，下面我们通过编码来实现ActivityManagerService：

    1、首先定义IActivityManager接口：声明binder描述符、方法编号、一个启动activity的方法即可。
    2、其次，实现ActivityManagerService侧的本地Binder对象基类ActivityManagerNative：
      重写asInterface方法，通过obj.queryLocalInterface查询本地Binder对象，如果没有则新建一个AMP远程代理对象。
      重写onTransact方法，通过code所对应的binder描述符做相应的处理，如果器对应的是启动activity的描述符，则做启动Activity的处理，并使用reply这个数据传递者将启动结果返回出去。

    3、接着，实现Client侧的代理对象ActivityManagerProxy：
      主要是重写startActivity()通信方法，通过Parcel.obtain()获取到data、reply这两个Parcel对象，然后将intent参数序列化，写入data中。接着调用BinderProxy对象的transact方法，交由Binder驱动处理。等待server执行结束后，通过reply.readInt()这样的读取方式读取执行结果。

    4、最后，实现Binder本地对象（IActivityManager接口）：重写startActivity方法，实现真正的启动活动逻辑。Client只需要获取到AMS的代理对象IActivityManager就可以通信了。

3、动画原理：
    分类：
      frame 帧动画：AnimationDrawable控制animation-list.xml布局。
      tween 补间动画：通过指定View的初末状态和变化方式，对View的内容完成一系列的图形变换来实现动画效果， Alpha, Scale ,Translate, Rotate。
      PropertyAnimation 属性动画：3.0引入，属性动画核心思想是对值的变化。

      属性动画&&补间动画的性能差异：
      属性动画操作的是对象的实例属性，例如translationX,然后反射调用set,geView动画:t方法，多个属性动画同时执行，会频繁反射调用类方法，降低性能。
      补间动画只产生了一个动画效果，其真实的坐标并没有发生改变，是效果一直在发生变化，没有频繁反射调用方法的耗费性能操作。

    原理及特点：
      帧动画：是在xml中定义好一系列图片之后，使用AnimatonDrawable来播放的动画。
      View动画：只是影像变化，view的实际位置还在原来地方。
      属性动画：
        插值器：作用是根据时间流逝的百分比来计算属性变化的百分比。
        估值器：在1的基础上由这个东西来计算出属性到底变化了多少数值的类
        其实就是利用插值器和估值器，来计出各个时刻View的属性，然后通过改变View的属性来实现View的动画效果。

      区别：
      属性动画才是真正的实现了 view 的移动，补间动画对view 的移动更像是在不同地方绘制了一个影子，实际对象还是处于原来的地方。 当动画的 repeatCount 设置为无限循环时，如果在Activity退出时没有及时将动画停止，属性动画会导致Activity无法释放而导致内存泄漏，而补间动画却没问题。 xml 文件实现的补间动画，复用率极高。在 Activity切换，窗口弹出时等情景中有着很好的效果。 使用帧动画时需要注意，不要使用过多特别大的图，容导致内存不足。
      为什么属性动画移动后仍可点击？
      播放补间动画的时候，我们所看到的变化，都只是临时的。而属性动画呢，它所改变的东西，却会更新到这个View所对应的矩阵中，所以当ViewGroup分派事件的时候，会正确的将当前触摸坐标，转换成矩阵变化后的坐标，这就是为什么播放补间动画不会改变触摸区域的原因了。

4、Https的连接过程，加解密算法的选择，以及为什么？

    加密算法的类型基本上分为了两种：
      对称加密，加密用的密钥和解密用的密钥是同一个，比较有代表性的就是 AES 加密算法；
      非对称加密，加密用的密钥称为公钥，解密用的密钥称为私钥，经常使用到的 RSA 加密算法就是非对称加密的
      Hash单向加密算法：HASH算法：MD5, SHA1, SHA256
      相比较对称加密而言，非对称加密安全性更高，但是加解密耗费的时间更长，速度慢。

    HTTPS = HTTP + SSL，HTTPS 的加密就是在 SSL 中完成的。

    这就要从 CA 证书讲起了。CA 证书其实就是数字证书，是由 CA 机构颁发的。至于 CA 机构的权威性，那么是毋庸置疑的，所有人都是信任它的。
    CA 证书内一般会包含以下内容：

      证书的颁发机构、版本
      证书的使用者
      证书的公钥
      证书的有效时间
      证书的数字签名 Hash 值和签名 Hash 算法

    客户端如何校验 CA 证书？

    CA 证书中的 Hash 值，其实是用证书的私钥进行加密后的值（证书的私钥不在 CA 证书中）。然后客户端得到证书后，利用证书中的公钥去解密该 Hash 值，
    得到 Hash-a ；然后再利用证书内的签名 Hash 算法去生成一个 Hash-b 。最后比较 Hash-a 和 Hash-b 这两个的值。
    如果相等，那么证明了该证书是对的，服务端是可以被信任的；如果不相等，那么就说明该证书是错误的，可能被篡改了，浏览器会给出相关提示，
    无法建立起 HTTPS 连接。除此之外，还会校验 CA 证书的有效时间和域名匹配等。

    HTTPS 中的 SSL 握手建立过程：

    假设现在有客户端 A 和服务器 B ：
      1、首先，客户端 A 访问服务器 B ，比如我们用浏览器打开一个网页 www.baidu.com ，这时，浏览器就是客户端 A ，百度的服务器就是服务器 B 了。这时候客户端 A 会生成一个随机数1，把随机数1 、自己支持的 SSL 版本号以及加密算法等这些信息告诉服务器 B 。
      2、服务器 B 知道这些信息后，然后确认一下双方的加密算法，然后服务端也生成一个随机数 2 ，并将随机数 2 和 CA 颁发给自己的证书一同返回给客户端 A 。
      3、客户端 A 得到 CA 证书后，会去校验该 CA 证书的有效性，校验方法在上面已经说过了。校验通过后，客户端生成一个随机数3 ，然后用证书中的公钥加密随机数3 并传输给服务端 B 。
      4、服务端 B 得到加密后的随机数3，然后利用私钥进行解密，得到真正的随机数3。
      5、最后，客户端 A 和服务端 B 都有随机数1、随机数2、随机数3，然后双方利用这三个随机数生成一个对话密钥。之后传输内容就是利用对话密钥来进行加解密了。这时就是利用了对称加密，一般用的都是 AES 算法。
      6、客户端 A 通知服务端 B ，指明后面的通讯用对话密钥来完成，同时通知服务器 B 客户端 A 的握手过程结束。
      7、服务端 B 通知客户端 A，指明后面的通讯用对话密钥来完成，同时通知客户端 A 服务器 B 的握手过程结束。
      8、SSL 的握手部分结束，SSL 安全通道的数据通讯开始，客户端 A 和服务器 B 开始使用相同的对话密钥进行数据通讯。

    简化如下：
    1、客户端和服务端建立 SSL 握手，客户端通过 CA 证书来确认服务端的身份；
    2、互相传递三个随机数，之后通过这三个随机数来生成一个密钥；
    3、互相确认密钥，然后握手结束；
    4、数据通讯开始，都使用同一个对话密钥来加解密；
    可以发现，在 HTTPS 加密原理的过程中把对称加密和非对称加密都利用了起来。即利用了非对称加密安全性高的特点，又利用了对称加密速度快，效率高的好处。
    5、TCP三次握手：

    重要标志位：
    ACK ：TCP协议规定，只有ACK=1时有效，也规定连接建立后所有发送的报文的ACK必须为1。
    SYN(SYNchronization) ：在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文。对方若同意建立连接，则应在响应报文中使SYN=1和ACK=1. 因此, SYN置1就表示这是一个连接请求或连接接受报文。
    FIN （finis）即完，终结的意思， 用来释放一个连接。当 FIN = 1 时，表明此报文段的发送方的数据已经发送完毕，并要求释放连接。
    
    三次握手、四次挥手过程：
      三次握手：
      第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，seq为x；然后，客户端进入SYN_SEND状态，等待服务器的确认；
      第二次握手：服务器收到SYN报文段，需要对这个SYN报文段进行确认，设置ACK为x+1(即seq+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，seq为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态；
      第三次握手：客户端收到服务器的SYN+ACK报文段。然后将ACK设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。
      
      四次挥手：
      第一次分手：主机1（可以使客户端，也可以是服务器端），设置seq和ACK，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态，这表示主机1没有数据要发送给主机2了；
      第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，ACK为seq加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求；
      第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态；
      第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。

    “三次握手”的目的：“为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误”。主要目的防止server端一直等待，浪费资源。换句话说，即是为了保证服务端能收接受到客户端的信息并能做出正确的应答而进行前两次(第一次和第二次)握手，为了保证客户端能够接收到服务端的信息并能做出正确的应答而进行后两次(第二次和第三次)握手。

    “四次挥手”的原因：因为tcp是全双工模式，接收到FIN时意味将没有数据再发来，但是还是可以继续发送数据。

6、组件化开发流程：
    分析现有的组件化方案：
    很多大厂的组件化方案是以 多工程 + 多 Module 的结构(微信, 美团等超级 App 更是以 多工程 + 多 Module + 多 P 工程(以页面为单元的代码隔离方式) 的三级工程结构), 使用 Git Submodule 创建多个子仓库管理各个模块的代码, 并将各个模块的代码打包成 AAR 上传至私有 Maven 仓库使用远程版本号依赖的方式进行模块间代码的隔离。

    组件化开发的好处：
    避免重复造轮子，可以节省开发和维护的成本。
    可以通过组件和模块为业务基准合理地安排人力，提高开发效率。
    不同的项目可以共用一个组件或模块，确保整体技术方案的统一性。
    为未来插件化共用同一套底层模型做准备。

    跨组件通信：
    跨组件通信场景：
    第一种是组件之间的页面跳转 (Activity 到 Activity, Fragment 到 Fragment, Activity 到 Fragment, Fragment 到 Activity) 以及跳转时的数据传递 (基础数据类型和可序列化的自定义类类型)。
    第二种是组件之间的自定义类和自定义方法的调用(组件向外提供服务)。

    跨组件通信方案分析：

    第一种组件之间的页面跳转不需要过多描述了, 算是 ARouter 中最基础的功能, API 也比较简单, 跳转时想传递不同类型的数据也提供有相应的 API。
    第二种组件之间的自定义类和自定义方法的调用要稍微复杂点, 需要 ARouter 配合架构中的 公共服务(CommonService) 实现：

    提供服务的业务模块：
    在公共服务(CommonService) 中声明 Service 接口 (含有需要被调用的自定义方法), 然后在自己的模块中实现这个 Service 接口, 再通过 ARouter API 暴露实现类。

    使用服务的业务模块：
    通过 ARouter 的 API 拿到这个 Service 接口(多态持有, 实际持有实现类), 即可调用 Service 接口中声明的自定义方法, 这样就可以达到模块之间的交互。
    此外，可以使用 AndroidEventBus 其独有的 Tag, 可以在开发时更容易定位发送事件和接受事件的代码, 如果以组件名来作为 Tag 的前缀进行分组, 也可以更好的统一管理和查看每个组件的事件, 当然也不建议大家过多使用 EventBus。
    如何管理过多的路由表？

    RouterHub 存在于基础库, 可以被看作是所有组件都需要遵守的通讯协议, 里面不仅可以放路由地址常量, 还可以放跨组件传递数据时命名的各种 Key 值, 再配以适当注释, 任何组件开发人员不需要事先沟通只要依赖了这个协议, 就知道了各自该怎样协同工作, 既提高了效率又降低了出错风险, 约定的东西自然要比口头上说强。
    Tips: 如果您觉得把每个路由地址都写在基础库的 RouterHub 中, 太麻烦了, 也可以在每个组件内部建立一个私有 RouterHub, 将不需要跨组件的路由地址放入私有 RouterHub 中管理, 只将需要跨组件的路由地址放入基础库的公有 RouterHub 中管理, 如果您不需要集中管理所有路由地址的话, 这也是比较推荐的一种方式。
    
    ARouter路由原理：
    ARouter维护了一个路由表Warehouse，其中保存着全部的模块跳转关系，ARouter路由跳转实际上还是调用了startActivity的跳转，使用了原生的Framework机制，只是通过apt注解的形式制造出跳转规则，并人为地拦截跳转和设置跳转条件。

7、如何绕过9.0限制？

    如何限制？
      1、阻止java反射和JNI。
      2、当获取方法或Field时进行检测。
      3、怎么检测？
      区分出是系统调用还是开发者调用：根据堆栈，回溯Class，查看ClassLoader是否是BootStrapClassLoader。
      区分后，再区分是否是hidden api：Method，Field都有access_flag，有一些备用字段，hidden信息存储其中。
    如何绕过？
      1、不用反射：
      利用一个fakelib，例如写一个android.app.ActivityThread#currentActivityThread空实现，直接调用；
      
      2、伪装系统调用：
      jni修改一个class的classloder为BootStrapClassLoader，麻烦。
      利用系统方法去反射：
      利用原反射，即：getDeclaredMethod这个方法是系统的方法，通过getDeclaredmethod反射去执行hidden api。
      
      3、修改Method，Field中存储hidden信息的字段：
      利用jni去修改。

8、堆内存，栈内存理解，栈如何转换成堆？
    在函数中定义的一些基本类型的变量和对象的引用变量都是在函数的栈内存中分配。
    堆内存用于存放由new创建的对象和数组。JVM里的“堆”（heap）特指用于存放Java对象的内存区域。所以根据这个定义，Java对象全部都在堆上。
    JVM的堆被同一个JVM实例中的所有Java线程共享。它通常由某种自动内存管理机制所管理，这种机制通常叫做“垃圾回收”（garbage collection，GC）。
    堆主要用来存放对象的，栈主要是用来执行程序的。实际上，栈中的变量指向堆内存中的变量，这就是 Java 中的指针!

9、hashcode（）和 equals（）的作用、区别、联系？
    因为hashCode()并不是完全可靠，有时候不同的对象他们生成的hashcode也会一样（生成hash值的公式可能存在的问题），
    所以hashCode()只能说是大部分时候可靠，并不是绝对可靠，所以我们可以得出：

    1、equal()相等的两个对象他们的hashCode()肯定相等，也就是用equal()对比是绝对可靠的。
    2、hashCode()相等的两个对象他们的equal()不一定相等，也就是hashCode()不是绝对可靠的。
    
10、Handler、Looper、MessageQueue、Thread关系？
    一个线程可以有多个Handler实例，一个线程对应一个Looper，一个Looper也只对应一个MessageQueue，一个MessageQueue对应多个Message和Runnable。
    所以就形成了一对多的对应关系，一方：线程、Looper、MessageQueue；多方：Handler、Message。
    同时可以看出另一个一对一关系：一个Message实例对应一个Handler实例。

11、Hashmap如何解决散列碰撞（必问）？
    Java中HashMap是利用“拉链法”处理HashCode的碰撞问题。在调用HashMap的put方法或get方法时，都会首先调用hashcode方法，去查找相关的key，当有冲突时，
    再调用equals方法。hashMap基于hasing原理，我们通过put和get方法存取对象。当我们将键值对传递给put方法时，他调用键对象的hashCode()方法来计算hashCode，
    然后找到bucket（哈希桶）位置来存储对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，
    当碰撞发生了，对象将会存储在链表的下一个节点中。hashMap在每个链表节点存储键值对对象。当两个不同的键却有相同的hashCode时，
    他们会存储在同一个bucket位置的链表中。键对象的equals()来找到键值对。


12、Hashmap底层为什么是线程不安全的？
    并发场景下使用时容易出现死循环，在 HashMap 扩容的时候会调用 resize() 方法，就是这里的并发操作容易在一个桶上形成环形链表；
    这样当获取一个不存在的 key 时，计算出的 index 正好是环形链表的下标就会出现死循环；
    在 1.7 中 hash 冲突采用的头插法形成的链表，在并发条件下会形成循环链表，一旦有查询落到了这个链表上，当获取不到值时就会死循环。

13、硬件加速的实现原理？
    通过底层软件代码，将CPU不擅长的图形计算转换成GPU专用指令，由GPU完成：
    CPU更擅长复杂逻辑控制，而GPU得益于大量ALU和并行结构设计，更擅长数学运算。
    页面由各种基础元素（DisplayList）构成，渲染时需要进行大量浮点运算。
    硬件加速条件下，CPU用于控制复杂绘制逻辑、构建或更新DisplayList；GPU用于完成图形计算、渲染DisplayList。
    硬件加速条件下，刷新界面尤其是播放动画时，CPU只重建或更新必要的DisplayList，进一步提高渲染效率。
    实现同样效果，应尽量使用更简单的DisplayList，从而达到更好的性能（Shape代替Bitmap等）。

14、handler postDelay这个延迟是怎么实现的？
    handler.postDelay并不是先等待一定的时间再放入到MessageQueue中，而是直接进入MessageQueue，以MessageQueue的时间顺序排列和唤醒的方式结合实现的。
    
15、断点续传实现？
    在本地下载过程中要使用数据库实时存储到底存储到文件的哪个位置了，这样点击开始继续传递时，才能通过HTTP的GET请求中的
    setRequestProperty("Range","bytes=startIndex-endIndex");方法可以告诉服务器，数据从哪里开始，到哪里结束。同时在本地的文件写入时，
    RandomAccessFile的seek()方法也支持在文件中的任意位置进行写入操作。最后通过广播或事件总线机制将子线程的进度告诉Activity的进度条。
    关于断线续传的HTTP状态码是206，即HttpStatus.SC_PARTIAL_CONTENT。

16、RxJava 变换操作符 map flatMap concatMap buffer？
    map：【数据类型转换】将被观察者发送的事件转换为另一种类型的事件。
    flatMap：【化解循环嵌套和接口嵌套】将被观察者发送的事件序列进行拆分 & 转换 后合并成一个新的事件序列，最后再进行发送。
    concatMap：【有序】与 flatMap 的 区别在于，拆分 & 重新合并生成的事件序列 的顺序与被观察者旧序列生产的顺序一致。
    buffer：定期从被观察者发送的事件中获取一定数量的事件并放到缓存区中，然后把这些数据集合打包发射。

17、Android中ClassLoader的种类&特点：
    BootClassLoader（Java的BootStrap ClassLoader）：用于加载Android Framework层class文件。
    PathClassLoader（Java的App ClassLoader）：用于加载已经安装到系统中的apk中的class文件。
    DexClassLoader（Java的Custom ClassLoader）：用于加载指定目录中的class文件。
    BaseDexClassLoader：是PathClassLoader和DexClassLoader的父类。
